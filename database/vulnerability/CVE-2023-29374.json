{
	"identifier": "CVE-2023-29374",
	"description": "In LangChain through 0.0.131, the LLMMathChain chain allows prompt injection attacks that can execute arbitrary code via the Python exec method.",
	"type": "none",
	"severity": "none",
	"state": "published",
	"datetime": "2023-04-05T00:15:37Z",
	"is_edited": false,
	"hardware": [],
	"software": [],
	"products": [
		{
			"name": "langchain",
			"version": "\u003c= 0.0.131",
			"architecture": "any",
			"vendor": "langchain",
			"type": "software",
			"is_edited": false,
			"aliases": []
		}
	],
	"references": [
		"https://github.com/hwchase17/langchain/issues/1026",
		"https://github.com/hwchase17/langchain/issues/814",
		"https://github.com/hwchase17/langchain/pull/1119",
		"https://twitter.com/rharang/status/1641899743608463365/photo/1"
	],
	"weaknesses": [
		"CWE-74"
	]
}